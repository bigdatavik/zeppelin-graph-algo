{
  "paragraphs": [
    {
      "text": "%pyspark\nfrom graphframes import *\n\n# // tag::imports[]\nfrom graphframes.lib import AggregateMessages as AM\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom operator import itemgetter\n\n\n# // tag::load-graph-frame[]\ndef create_social_graph():\n    nodes \u003d spark.read.csv(\"spark-warehouse/social-nodes.csv\", header\u003dTrue)\n    relationships \u003d spark.read.csv(\"spark-warehouse/social-relationships.csv\", header\u003dTrue)\n    return GraphFrame(nodes, relationships)\n# // end::load-graph-frame[]\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:33.765",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898758918_1863761156",
      "id": "20200101-112344_1237781185",
      "dateCreated": "2020-01-01 17:12:38.918",
      "dateStarted": "2020-01-01 17:33:33.923",
      "dateFinished": "2020-01-01 17:33:47.955",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef collect_paths(paths):\n    return F.collect_set(paths)\n\n\ncollect_paths_udf \u003d F.udf(collect_paths, ArrayType(StringType()))\n\npaths_type \u003d ArrayType(\n    StructType([StructField(\"id\", StringType()), StructField(\"distance\", IntegerType())]))\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:47.963",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898810401_-57544950",
      "id": "20200101-171330_1722941153",
      "dateCreated": "2020-01-01 17:13:30.401",
      "dateStarted": "2020-01-01 17:33:48.071",
      "dateFinished": "2020-01-01 17:33:48.082",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef flatten(ids):\n    flat_list \u003d [item for sublist in ids for item in sublist]\n    return list(dict(sorted(flat_list, key\u003ditemgetter(0))).items())\n\n\nflatten_udf \u003d F.udf(flatten, paths_type)\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:48.165",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898817814_1286585316",
      "id": "20200101-171337_559107504",
      "dateCreated": "2020-01-01 17:13:37.814",
      "dateStarted": "2020-01-01 17:33:48.234",
      "dateFinished": "2020-01-01 17:33:48.273",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef new_paths(paths, id):\n    paths \u003d [{\"id\": col1, \"distance\": col2 + 1} for col1, col2 in paths if col1 !\u003d id]\n    paths.append({\"id\": id, \"distance\": 1})\n    return paths\n\n\nnew_paths_udf \u003d F.udf(new_paths, paths_type)\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:48.320",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898834643_766824371",
      "id": "20200101-171354_1350292755",
      "dateCreated": "2020-01-01 17:13:54.643",
      "dateStarted": "2020-01-01 17:33:48.402",
      "dateFinished": "2020-01-01 17:33:48.435",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef merge_paths(ids, new_ids, id):\n    joined_ids \u003d ids + (new_ids if new_ids else [])\n    merged_ids \u003d [(col1, col2) for col1, col2 in joined_ids if col1 !\u003d id]\n    best_ids \u003d dict(sorted(merged_ids, key\u003ditemgetter(1), reverse\u003dTrue))\n    return [{\"id\": col1, \"distance\": col2} for col1, col2 in best_ids.items()]\n\n\nmerge_paths_udf \u003d F.udf(merge_paths, paths_type)\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:48.501",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898841166_693072570",
      "id": "20200101-171401_953277830",
      "dateCreated": "2020-01-01 17:14:01.167",
      "dateStarted": "2020-01-01 17:33:48.558",
      "dateFinished": "2020-01-01 17:33:48.577",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef calculate_closeness(ids):\n    nodes \u003d len(ids)\n    total_distance \u003d sum([col2 for col1, col2 in ids])\n    return 0 if total_distance \u003d\u003d 0 else nodes * 1.0 / total_distance\n\n\ncloseness_udf \u003d F.udf(calculate_closeness, DoubleType())\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:33:48.657",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1577898860024_-1055128335",
      "id": "20200101-171420_1755424301",
      "dateCreated": "2020-01-01 17:14:20.024",
      "dateStarted": "2020-01-01 17:33:48.706",
      "dateFinished": "2020-01-01 17:33:48.722",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\ndef create_social_graph():\n    nodes \u003d spark.read.csv(\"spark-warehouse/social-nodes.csv\", header\u003dTrue)\n    relationships \u003d spark.read.csv(\"spark-warehouse/social-relationships.csv\", header\u003dTrue)\n    return GraphFrame(nodes, relationships)\n    \ng \u003d create_social_graph()",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:34:03.234",
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.25.0.3:4040/jobs/job?id\u003d0",
            "http://172.25.0.3:4040/jobs/job?id\u003d1"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1577898758923_-1305865509",
      "id": "20200101-112422_199127971",
      "dateCreated": "2020-01-01 17:12:38.924",
      "dateStarted": "2020-01-01 17:34:03.315",
      "dateFinished": "2020-01-01 17:34:06.210",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\nvertices \u003d g.vertices.withColumn(\"ids\", F.array())\ncached_vertices \u003d AM.getCachedDataFrame(vertices)\ng2 \u003d GraphFrame(cached_vertices, g.edges)\n\nfor i in range(0, g2.vertices.count()):\n    msg_dst \u003d new_paths_udf(AM.src[\"ids\"], AM.src[\"id\"])\n    msg_src \u003d new_paths_udf(AM.dst[\"ids\"], AM.dst[\"id\"])\n    agg \u003d g2.aggregateMessages(F.collect_set(AM.msg).alias(\"agg\"),\n                               sendToSrc\u003dmsg_src, sendToDst\u003dmsg_dst)\n    res \u003d agg.withColumn(\"newIds\", flatten_udf(\"agg\")).drop(\"agg\")\n    new_vertices \u003d (g2.vertices.join(res, on\u003d\"id\", how\u003d\"left_outer\")\n                    .withColumn(\"mergedIds\", merge_paths_udf(\"ids\", \"newIds\", \"id\"))\n                    .drop(\"ids\", \"newIds\")\n                    .withColumnRenamed(\"mergedIds\", \"ids\"))\n    cached_new_vertices \u003d AM.getCachedDataFrame(new_vertices)\n    g2 \u003d GraphFrame(cached_new_vertices, g2.edges)\n\n(g2.vertices\n .withColumn(\"closeness\", closeness_udf(\"ids\"))\n .sort(\"closeness\", ascending\u003dFalse)\n .show(truncate\u003dFalse))\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:34:08.233",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/python"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+------------------------------------------------------------+------------------+\n|id     |ids                                                         |closeness         |\n+-------+------------------------------------------------------------+------------------+\n|Alice  |[[Bridget,1], [Doug,1], [Charles,1], [Michael,1], [Mark,1]] |1.0               |\n|Doug   |[[Bridget,1], [Charles,1], [Michael,1], [Mark,1], [Alice,1]]|1.0               |\n|David  |[[James,1], [Amy,1]]                                        |1.0               |\n|Bridget|[[Doug,1], [Charles,2], [Michael,1], [Mark,2], [Alice,1]]   |0.7142857142857143|\n|Michael|[[Bridget,1], [Doug,1], [Charles,2], [Mark,2], [Alice,1]]   |0.7142857142857143|\n|James  |[[David,1], [Amy,2]]                                        |0.6666666666666666|\n|Amy    |[[James,2], [David,1]]                                      |0.6666666666666666|\n|Charles|[[Bridget,2], [Doug,1], [Michael,2], [Mark,2], [Alice,1]]   |0.625             |\n|Mark   |[[Bridget,2], [Doug,1], [Charles,2], [Michael,2], [Alice,1]]|0.625             |\n+-------+------------------------------------------------------------+------------------+\n\n"
          }
        ]
      },
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            "http://172.25.0.3:4040/jobs/job?id\u003d2",
            "http://172.25.0.3:4040/jobs/job?id\u003d3",
            "http://172.25.0.3:4040/jobs/job?id\u003d4",
            "http://172.25.0.3:4040/jobs/job?id\u003d5",
            "http://172.25.0.3:4040/jobs/job?id\u003d6",
            "http://172.25.0.3:4040/jobs/job?id\u003d7",
            "http://172.25.0.3:4040/jobs/job?id\u003d8",
            "http://172.25.0.3:4040/jobs/job?id\u003d9",
            "http://172.25.0.3:4040/jobs/job?id\u003d10",
            "http://172.25.0.3:4040/jobs/job?id\u003d11",
            "http://172.25.0.3:4040/jobs/job?id\u003d12"
          ],
          "interpreterSettingId": "spark"
        }
      },
      "apps": [],
      "jobName": "paragraph_1577898878374_1854226027",
      "id": "20200101-171438_937517174",
      "dateCreated": "2020-01-01 17:14:38.374",
      "dateStarted": "2020-01-01 17:34:08.303",
      "dateFinished": "2020-01-01 17:46:04.941",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%pyspark\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-01 17:34:03.239",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1577900043234_-1601049326",
      "id": "20200101-173403_1355836395",
      "dateCreated": "2020-01-01 17:34:03.234",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Centrality/Closeness/Spark",
  "id": "2EY9G1KBV",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}